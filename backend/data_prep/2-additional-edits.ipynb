{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc0db75",
   "metadata": {},
   "outputs": [],
   "source": [
    "import asyncio\n",
    "from googletrans import Translator\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1480c76",
   "metadata": {},
   "source": [
    "# Multi-character word dataset improvement : ensuring data quality"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93b1a7ed",
   "metadata": {},
   "source": [
    "It is clear from tests that the final csv file used to generate the json for multi-character words has a few errors. Many words lack pronunciations, and some lack valid definitions (only containing pinyin without context). We use a google translate API to fix some. First, we replace all pronunciations using google translate. Then, we check for syllables with accent marks in the definitions, and find definitions using the same API for definitions with only pinyin (no real meaning given)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8fb0bee",
   "metadata": {},
   "source": [
    "#### Reading in the data and testing translator apis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af47c4c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = \"test_multi_list.csv\" #\"final_test_characters.csv\"\n",
    "test_data = pd.read_csv(path)\n",
    "print(len(test_data))\n",
    "test_data.head(n=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45ec2c27",
   "metadata": {},
   "source": [
    "Testing translator API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d402b634",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def chinese_to_eng(input):\n",
    "    translator = Translator()\n",
    "    result = await translator.translate(input, dest=\"en\", src=\"zh\")\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e0ccc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await chinese_to_eng(\"我的\")\n",
    "print(\"definition:\", result.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3729d0fc",
   "metadata": {},
   "source": [
    "This is the full data that can be gained. Note extracting pinyin is not as direct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d015a5f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"pronunciation (pinyin):\", result.extra_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0acc4527",
   "metadata": {},
   "source": [
    "More examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a046a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await chinese_to_eng(\"他是說漢語的\")\n",
    "print(result.extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c20175d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await chinese_to_eng(\"他是說漢語的\")\n",
    "print(result.extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acfe2790",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "result = await chinese_to_eng(\"的确\")\n",
    "print(result.extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d344a53",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "result = await chinese_to_eng(\"高的\")\n",
    "print(result.extra_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "931254e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "curr = result.extra_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f539c8e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(curr[\"translation\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdf3ed76",
   "metadata": {},
   "source": [
    "#### Writing function to extract pinyin\n",
    "\n",
    "From this, we can extract pinyin using this pattern. Check for none, return error for potential issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae2313c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def getPinyin(input): \n",
    "    try :\n",
    "        result = await chinese_to_eng(input)\n",
    "        result = result.extra_data\n",
    "        final_list = result[\"translation\"]\n",
    "        final_list = final_list[len(final_list)-1]\n",
    "        pinyin = final_list[len(final_list)-1]\n",
    "        if (pinyin is None): \n",
    "            return \"\"\n",
    "        else:\n",
    "            return pinyin\n",
    "    except :\n",
    "        return \"error\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "27ef49fa",
   "metadata": {},
   "source": [
    "testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e79fc1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinyin = await getPinyin(\"高的\")\n",
    "print(pinyin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d179521",
   "metadata": {},
   "outputs": [],
   "source": [
    "pinyin = await getPinyin(\"台湾作词人，音乐人[1]。現為大國大熊星娛樂总经理。曾擔任台湾科藝百代（EMI）及维京音乐（Virgin Music Chinese）、新力哥倫比亞音樂、點將唱片的总经理。二十年来，打造出林慧萍、張清芳、伍思凱、優客李林、柯以敏、萧亚轩、刘若英、李玟、赵薇、江美琪、余憲忠等歌手[2]。个人发表原创歌词600多首，包括许多脍炙人口的作品。\")\n",
    "print(pinyin)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48242808",
   "metadata": {},
   "source": [
    "##### pinyin validation\n",
    "\n",
    "We can help validate for chinese character-only inputs by checking if the pinyin is valid. We can check if every character is represented by one pinyin. Do a simple check we were check if the number of chinese characters equals the number of vowel clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ec70ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "import unicodedata\n",
    "\n",
    "def count_vowel_clusters(s):\n",
    "    vowels = \"aeiouAEIOU\"\n",
    "    cluster_count = 0\n",
    "    in_cluster = False\n",
    "\n",
    "    for char in s:\n",
    "        #remove diacritics \n",
    "        modified_char = unicodedata.normalize('NFD', char)\n",
    "        modified_char = str(modified_char.encode('ascii', 'ignore').decode(\"utf-8\"))\n",
    "        if modified_char in vowels:\n",
    "            if not in_cluster:\n",
    "                cluster_count += 1  # Start a new cluster\n",
    "                in_cluster = True\n",
    "        else:\n",
    "            in_cluster = False             # Not a vowel, so any current cluster ends\n",
    "\n",
    "            \n",
    "    return cluster_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42106a69",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import string \n",
    "\n",
    "def contains_chinese(text):\n",
    "    #Checks if the input string contains any Chinese character\n",
    "    # Regex pattern for the main CJK Unified Ideographs range\n",
    "    chinese_pattern = re.compile(r'[\\u4e00-\\u9fff]')\n",
    "    return bool(chinese_pattern.search(text))\n",
    "#loop through a word (unicode parts to see if all are chinese or punctuation)\n",
    "\n",
    "def allChinese(text):\n",
    "    punctuations = set(string.punctuation) \n",
    "    for char in text:\n",
    "        #return false if the current character is not chinese and is not punctuation\n",
    "        if (contains_chinese(char) == False and char not in punctuations):\n",
    "            return False\n",
    "    return True\n",
    "# count, using similar logic, the number of chinese characters in text \n",
    "def numChinese(text):\n",
    "    count = 0\n",
    "    for char in text:\n",
    "        if contains_chinese(char) == True:\n",
    "            count+=1\n",
    "    return count"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1482c3e",
   "metadata": {},
   "source": [
    "Testing the functions (by default python does not tells difference between diacritics, so we need to remove the accent marks). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "264c58cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(count_vowel_clusters(\"xiāoyàxuān\"))\n",
    "\n",
    "print(count_vowel_clusters(\"liúruòyīng\"))\n",
    "\n",
    "print(count_vowel_clusters(\"gēshǒu\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12c2150",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( allChinese(\"da國大熊星\") )\n",
    "\n",
    "print( allChinese(\"國大熊星\") )\n",
    "\n",
    "print( allChinese(\"國大-=/熊星\") )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "392c192a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print( numChinese(\"da國大熊星\") )\n",
    "print( numChinese(\"國大熊星-大熊星-\") )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "affbc634",
   "metadata": {},
   "source": [
    "##### Final version of the function\n",
    "\n",
    "We complete the function by adding the case if the text is all chinese, the pinyin condition must match"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f02b15f",
   "metadata": {},
   "outputs": [],
   "source": [
    "async def getPinyin(input): \n",
    "    try :\n",
    "        result = await chinese_to_eng(input)\n",
    "        result = result.extra_data\n",
    "        final_list = result[\"translation\"]\n",
    "        final_list = final_list[len(final_list)-1]\n",
    "        pinyin = final_list[len(final_list)-1]\n",
    "        if (pinyin is None): \n",
    "            print(\"no pinyin was able to be returned for\", input)\n",
    "            return \"\"\n",
    "        if (allChinese(input)==True and numChinese(input) != count_vowel_clusters(pinyin)): \n",
    "            print(\"error: output pinyin: \", pinyin, \"not valid for\", input)\n",
    "            return \"\"\n",
    "        else:\n",
    "            return pinyin\n",
    "    except Exception as e:\n",
    "        print(\"error: \",e , \"for\", input)\n",
    "        return \"\","
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68efb7f2",
   "metadata": {},
   "source": [
    "Verifying"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d84df479",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await getPinyin(\"國大熊星\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9b4906f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0e6083d",
   "metadata": {},
   "outputs": [],
   "source": [
    "result = await getPinyin(\"國大熊星-大熊星\")\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479fad39",
   "metadata": {},
   "source": [
    "#### Creating function to detect pinyin and chinese characters, to see what the text without it looks like, so we can determine if the definition is valid"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "989628fd",
   "metadata": {},
   "source": [
    "Create a function to check if a word is a pure english word (no diacritics or nonlatin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed86a0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_plain_latin(char):\n",
    "  #Checks if a character is a plain, unmarked Latin letter or punctuation\n",
    "  punctuations = set(string.punctuation) \n",
    "  return (char in string.ascii_letters or char in punctuations)\n",
    "def word_plain_latin(word):\n",
    "    for x in word:\n",
    "       if (is_plain_latin(x) == False):\n",
    "          return False\n",
    "    return True\n",
    "#isolate words of a sentence that only have plain latin characters into a string\n",
    "def plainLatinCharsWord(input):\n",
    "  words = input.split(\" \")\n",
    "  finalword = \"\"\n",
    "  for word in words:\n",
    "     if word_plain_latin(word):\n",
    "        finalword += (word+\" \")\n",
    "  return finalword.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "170dd8cc",
   "metadata": {},
   "source": [
    "Testing.\n",
    "\n",
    "As you can see, it reduces the complicated definitions to the chinese characters only"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10ba97cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plainLatinCharsWord(\"是的 shìde that's it, that's right 是的\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2fc295",
   "metadata": {},
   "source": [
    "### Data modification\n",
    "\n",
    "After running all of this, ideally no errors should remain when running again"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee8b7ab6",
   "metadata": {},
   "source": [
    "Check if the all the different words in the list are actually purely Chinese"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8c08bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "chars_list = list(test_data[\"word/character\"])\n",
    "print(len(chars_list))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69563e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for word in chars_list:\n",
    "    if allChinese(word) == False:\n",
    "        print(word, \"at index\", i, \"is not all chinese\")\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fb99279",
   "metadata": {},
   "source": [
    "As we can see there are no such errors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88859878",
   "metadata": {},
   "source": [
    "Modify the definitions list to make sure that all are valid definitions. If not, we use google translate to help"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a48916",
   "metadata": {},
   "outputs": [],
   "source": [
    "definitions = list(test_data[\"definition\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58c28a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 #track index\n",
    "for word in definitions:\n",
    "    word = str(word)\n",
    "    #isolate pure latin characters \n",
    "    latin = plainLatinCharsWord(word)\n",
    "    if len(latin)<4: #if the length is less than 4, the definition is likely not valid\n",
    "        print(\"definition:\", word, \"at index\", i, \"is not a valid definition, changing using google translator\")\n",
    "        currchar = chars_list[i] #get current character using previous list\n",
    "        newdef = await chinese_to_eng(currchar)\n",
    "        newdef = newdef.text\n",
    "        definitions[i] = newdef\n",
    "        print(\"changed definition of\",currchar, \"to \", newdef)\n",
    "        \n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c83883b8",
   "metadata": {},
   "source": [
    "Save updated data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a9c864e",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"definition\"] = definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b8fb5ab",
   "metadata": {},
   "source": [
    "Finally, we fix invalid pronuniciations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57203d43",
   "metadata": {},
   "outputs": [],
   "source": [
    "pronunciations = list(test_data[\"pronunciation\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73fc0ad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0 #track index\n",
    "for pron in pronunciations:\n",
    "    currchar = chars_list[i] #get current character using previous list\n",
    "    #check if it is valid by counting vowel clusters, and ensuring there are no chinese characters \n",
    "    if numChinese(currchar) != count_vowel_clusters(pron):\n",
    "        print(\"fix index \", i)\n",
    "        #print(f\"{i} invalid pronunciation\", pron, \"found for word\", currchar)\n",
    "        #attempt repair \n",
    "        result = await getPinyin(currchar)\n",
    "        if (result != \"\"):\n",
    "            #assign if correct\n",
    "            pronunciations[i] = result \n",
    "            #print(\"new pronunciation: \", result)\n",
    "        else:\n",
    "            print(\"failed repair at index\", i)\n",
    "\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e643f5",
   "metadata": {},
   "source": [
    "after these few errors, we change manually add pronunciations for :\n",
    "国民党, 乱麻麻, 屎壳郎, 伸懶腰 for test_multi_list.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df22bdc3",
   "metadata": {},
   "source": [
    "save changes \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e772be0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"pronunciation\"] = pronunciations"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98aaabe3",
   "metadata": {},
   "source": [
    "#### Finally, save this modified data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e21c5c76",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv(path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2fee9573",
   "metadata": {},
   "source": [
    "### Last part : changing column name to full pronunciation, and creating a column with the pronunciation without tones (full_pronunciation_wo), similar to that in final_test_characters.csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f4388df",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.rename(columns={'pronunciation': 'full_pronunciation'})\n",
    "test_data.head(n=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7dad868e",
   "metadata": {},
   "source": [
    "Stripping diacritics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c5f6e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "full_pronunciation_wo = list(test_data[\"full_pronunciation\"])\n",
    "i = 0\n",
    "for pro in full_pronunciation_wo:\n",
    "    #loop through each letter in pro to remove diacritic \n",
    "    modified_pro = \"\"\n",
    "    for char in pro:\n",
    "        #remove diacritics \n",
    "        modified_char = unicodedata.normalize('NFD', char)\n",
    "        modified_char = str(modified_char.encode('ascii', 'ignore').decode(\"utf-8\"))\n",
    "        modified_pro += modified_char\n",
    "    print(\"modified, \", modified_pro, \"current\", pro)\n",
    "    full_pronunciation_wo[i] = modified_pro\n",
    "    i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcb797f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data[\"full_pronunciation_wo\"] = full_pronunciation_wo\n",
    "test_data.head(n=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc2336cd",
   "metadata": {},
   "source": [
    "### Final part: saving data to export JSON. This is the same from before"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe3aefa",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data = test_data.loc[:, ~test_data.columns.str.startswith('Unnamed:')] #no unamed columns\n",
    "test_data.to_csv(path)\n",
    "test_data = pd.read_csv(path, index_col=0)\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce28f5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting traditional characters data\n",
    "our_data = test_data[test_data[\"code\"] == \"t\"]\n",
    "\n",
    "json_index = our_data.to_json(orient='index')\n",
    "\n",
    "# Print the JSON string\n",
    "print(json_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d364c2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exporting simplified characters data\n",
    "\n",
    "our_data = test_data[test_data[\"code\"] == \"s\"]\n",
    "\n",
    "json_index = our_data.to_json(orient='index')\n",
    "\n",
    "# Print the JSON string\n",
    "print(json_index)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
